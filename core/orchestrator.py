#!/usr/bin/env python3
"""
Orquestrador Principal - Social Media AI System

Este m√≥dulo implementa o orquestrador principal que coordena os 4 agentes
especializados usando CrewAI, gerencia o fluxo de aprova√ß√£o e implementa
o sistema de feedback entre agentes.

Funcionalidades:
- Coordena√ß√£o sequencial dos 4 agentes
- Sistema de aprova√ß√£o/rejei√ß√£o do Editor
- Feedback loop entre agentes
- M√©tricas de qualidade e performance
- Retry autom√°tico com melhorias

Autor: Sistema de IA Colaborativo
Vers√£o: 1.0.0 - Fase 3
"""

import asyncio
import logging
import time
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum

# CrewAI Imports
try:
    from crewai import Agent, Task, Crew, Process
    from crewai.tools import BaseTool
    CREWAI_AVAILABLE = True
except ImportError:
    CREWAI_AVAILABLE = False
    logging.warning("CrewAI n√£o dispon√≠vel")

from config.settings import SystemSettings
from core.agents import (
    SocialMediaAgents, 
    ContentRequest, 
    CrewResult, 
    AgentResult,
    social_agents
)
from core.llm_manager import llm_manager

class OrchestrationStatus(Enum):
    """Status da orquestra√ß√£o"""
    IDLE = "idle"
    RESEARCH = "research"
    WRITING = "writing"  
    VISUAL = "visual"
    EDITING = "editing"
    APPROVED = "approved"
    REJECTED = "rejected"
    ERROR = "error"
    RETRY = "retry"

class ApprovalDecision(Enum):
    """Decis√µes de aprova√ß√£o do Editor"""
    APPROVED = "approved"
    REJECTED = "rejected"
    NEEDS_REVISION = "needs_revision"
    PENDING = "pending"

@dataclass
class OrchestrationMetrics:
    """M√©tricas da orquestra√ß√£o"""
    total_executions: int = 0
    successful_executions: int = 0
    failed_executions: int = 0
    avg_execution_time: float = 0.0
    avg_retries: float = 0.0
    approval_rate: float = 0.0
    agent_performance: Dict[str, float] = field(default_factory=dict)
    cost_tracking: Dict[str, float] = field(default_factory=dict)

@dataclass
class QualityFeedback:
    """Feedback de qualidade entre agentes"""
    from_agent: str
    to_agent: str
    feedback_type: str  # "improvement", "error", "suggestion"
    message: str
    severity: str  # "low", "medium", "high", "critical"
    timestamp: datetime
    resolved: bool = False

@dataclass
class ExecutionContext:
    """Contexto de execu√ß√£o da orquestra√ß√£o"""
    request: ContentRequest
    status: OrchestrationStatus
    current_agent: Optional[str] = None
    start_time: Optional[datetime] = None
    agent_results: List[AgentResult] = field(default_factory=list)
    feedback_history: List[QualityFeedback] = field(default_factory=list)
    retry_count: int = 0
    max_retries: int = 3
    approval_decision: ApprovalDecision = ApprovalDecision.PENDING
    editor_feedback: Optional[str] = None

class ContentOrchestrator:
    """Orquestrador principal do sistema de cria√ß√£o de conte√∫do"""
    
    def __init__(self):
        """Inicializa o orquestrador"""
        self.logger = logging.getLogger(__name__)
        
        if not CREWAI_AVAILABLE:
            raise RuntimeError("CrewAI n√£o est√° dispon√≠vel. Execute: pip install crewai")
        
        # Configura√ß√µes
        self.max_concurrent_executions = SystemSettings.ORCHESTRATOR_CONFIG.max_concurrent_executions
        self.default_timeout = SystemSettings.ORCHESTRATOR_CONFIG.execution_timeout
        self.quality_threshold = SystemSettings.ORCHESTRATOR_CONFIG.quality_threshold
        
        # Estado interno
        self.active_executions: Dict[str, ExecutionContext] = {}
        self.execution_history: List[ExecutionContext] = []
        self.metrics = OrchestrationMetrics()
        
        # Sistema de agentes
        self.agents_system = social_agents
        
        # Feedback system
        self.feedback_processors = {
            "research_to_writing": self._process_research_feedback,
            "writing_to_visual": self._process_writing_feedback,
            "visual_to_editing": self._process_visual_feedback,
            "editing_to_all": self._process_editor_feedback
        }
        
        self.logger.info("üé¨ Orquestrador de Conte√∫do inicializado")
    
    async def create_content(
        self,
        request: ContentRequest,
        execution_id: Optional[str] = None
    ) -> CrewResult:
        """
        Ponto de entrada principal para cria√ß√£o de conte√∫do
        
        Args:
            request: Solicita√ß√£o de conte√∫do
            execution_id: ID √∫nico da execu√ß√£o (opcional)
            
        Returns:
            CrewResult: Resultado completo da execu√ß√£o
        """
        if execution_id is None:
            execution_id = f"exec_{int(time.time())}_{hash(request.topic) % 10000}"
        
        # Verificar limite de execu√ß√µes concorrentes
        if len(self.active_executions) >= self.max_concurrent_executions:
            raise RuntimeError(
                f"Limite de execu√ß√µes concorrentes excedido: "
                f"{len(self.active_executions)}/{self.max_concurrent_executions}"
            )
        
        # Criar contexto de execu√ß√£o
        context = ExecutionContext(
            request=request,
            status=OrchestrationStatus.IDLE,
            start_time=datetime.now()
        )
        
        self.active_executions[execution_id] = context
        
        try:
            self.logger.info(
                f"üöÄ Iniciando cria√ß√£o de conte√∫do [ID: {execution_id}]: {request.topic}"
            )
            
            # Executar fluxo principal
            result = await self._execute_orchestration_flow(execution_id, context)
            
            # Atualizar m√©tricas
            self._update_metrics(context, result)
            
            # Mover para hist√≥rico
            self.execution_history.append(context)
            del self.active_executions[execution_id]
            
            self.logger.info(
                f"‚úÖ Conte√∫do criado com sucesso [ID: {execution_id}]: "
                f"{result.approval_status} em {result.total_execution_time:.2f}s"
            )
            
            return result
            
        except Exception as e:
            context.status = OrchestrationStatus.ERROR
            self.logger.error(f"‚ùå Erro na cria√ß√£o de conte√∫do [ID: {execution_id}]: {e}")
            
            # Criar resultado de erro
            error_result = CrewResult(
                request=request,
                success=False,
                final_content="",
                agent_results=context.agent_results,
                total_execution_time=(datetime.now() - context.start_time).total_seconds(),
                approval_status="error",
                revision_feedback=str(e)
            )
            
            # Atualizar m√©tricas de erro
            self.metrics.failed_executions += 1
            
            # Mover para hist√≥rico
            self.execution_history.append(context)
            if execution_id in self.active_executions:
                del self.active_executions[execution_id]
            
            return error_result
    
    async def _execute_orchestration_flow(
        self, 
        execution_id: str, 
        context: ExecutionContext
    ) -> CrewResult:
        """Executa o fluxo principal de orquestra√ß√£o"""
        
        retry_count = 0
        while retry_count <= context.max_retries:
            try:
                # Executar sequ√™ncia de agentes
                context.status = OrchestrationStatus.RESEARCH
                research_result = await self._execute_research_phase(context)
                
                context.status = OrchestrationStatus.WRITING
                writing_result = await self._execute_writing_phase(context, research_result)
                
                context.status = OrchestrationStatus.VISUAL
                visual_result = await self._execute_visual_phase(context, writing_result)
                
                context.status = OrchestrationStatus.EDITING
                editing_result = await self._execute_editing_phase(
                    context, research_result, writing_result, visual_result
                )
                
                # Processar decis√£o do editor
                approval_decision = self._parse_editor_decision(editing_result)
                context.approval_decision = approval_decision
                
                if approval_decision == ApprovalDecision.APPROVED:
                    context.status = OrchestrationStatus.APPROVED
                    return self._create_final_result(context, editing_result)
                
                elif approval_decision == ApprovalDecision.REJECTED:
                    context.status = OrchestrationStatus.REJECTED
                    
                    if retry_count >= context.max_retries:
                        return self._create_rejection_result(context, editing_result)
                    
                    # Processar feedback e tentar novamente
                    await self._process_rejection_feedback(context, editing_result)
                    retry_count += 1
                    context.retry_count = retry_count
                    context.status = OrchestrationStatus.RETRY
                    
                    self.logger.info(
                        f"üîÑ Tentativa {retry_count}/{context.max_retries} "
                        f"[ID: {execution_id}]: processando feedback do editor"
                    )
                    
                elif approval_decision == ApprovalDecision.NEEDS_REVISION:
                    # Implementar l√≥gica espec√≠fica de revis√£o
                    await self._process_revision_feedback(context, editing_result)
                    retry_count += 1
                    context.retry_count = retry_count
                    
                else:
                    raise RuntimeError("Decis√£o de aprova√ß√£o n√£o reconhecida")
                    
            except Exception as e:
                self.logger.error(f"Erro na execu√ß√£o do fluxo: {e}")
                if retry_count >= context.max_retries:
                    raise
                retry_count += 1
        
        # Se chegou aqui, excedeu tentativas
        context.status = OrchestrationStatus.REJECTED
        return self._create_max_retries_result(context)
    
    async def _execute_research_phase(self, context: ExecutionContext) -> AgentResult:
        """Executa a fase de pesquisa"""
        context.current_agent = "researcher"
        start_time = time.time()
        
        try:
            # Criar tarefa de pesquisa
            task = self.agents_system.create_research_task(context.request)
            agent = self.agents_system._agents["researcher"]
            
            # Executar tarefa
            result = agent.execute_task(task)
            
            # Criar resultado estruturado
            agent_result = AgentResult(
                agent_name="researcher",
                success=True,
                content=str(result),
                metadata={
                    "task_description": task.description,
                    "expected_output": task.expected_output
                },
                execution_time=time.time() - start_time
            )
            
            context.agent_results.append(agent_result)
            
            self.logger.info(
                f"üîç Fase de pesquisa conclu√≠da em {agent_result.execution_time:.2f}s"
            )
            
            return agent_result
            
        except Exception as e:
            agent_result = AgentResult(
                agent_name="researcher",
                success=False,
                content="",
                metadata={},
                execution_time=time.time() - start_time,
                error_message=str(e)
            )
            
            context.agent_results.append(agent_result)
            raise RuntimeError(f"Erro na fase de pesquisa: {e}")
    
    async def _execute_writing_phase(
        self, 
        context: ExecutionContext, 
        research_result: AgentResult
    ) -> AgentResult:
        """Executa a fase de reda√ß√£o"""
        context.current_agent = "writer"
        start_time = time.time()
        
        try:
            # Criar tarefa de escrita com contexto da pesquisa
            task = self.agents_system.create_writing_task(context.request)
            agent = self.agents_system._agents["writer"]
            
            # Adicionar contexto da pesquisa
            enhanced_description = f"""
            {task.description}
            
            **CONTEXTO DA PESQUISA:**
            {research_result.content}
            
            Use essas informa√ß√µes para criar conte√∫do mais preciso e relevante.
            """
            task.description = enhanced_description
            
            # Executar tarefa
            result = agent.execute_task(task)
            
            # Criar resultado estruturado
            agent_result = AgentResult(
                agent_name="writer",
                success=True,
                content=str(result),
                metadata={
                    "task_description": task.description,
                    "research_context": research_result.content[:500] + "...",
                    "platforms": context.request.platforms
                },
                execution_time=time.time() - start_time
            )
            
            context.agent_results.append(agent_result)
            
            # Processar feedback research -> writing
            await self._generate_inter_agent_feedback(
                "research_to_writing", research_result, agent_result, context
            )
            
            self.logger.info(
                f"‚úçÔ∏è Fase de reda√ß√£o conclu√≠da em {agent_result.execution_time:.2f}s"
            )
            
            return agent_result
            
        except Exception as e:
            agent_result = AgentResult(
                agent_name="writer",
                success=False,
                content="",
                metadata={},
                execution_time=time.time() - start_time,
                error_message=str(e)
            )
            
            context.agent_results.append(agent_result)
            raise RuntimeError(f"Erro na fase de reda√ß√£o: {e}")
    
    async def _execute_visual_phase(
        self, 
        context: ExecutionContext, 
        writing_result: AgentResult
    ) -> AgentResult:
        """Executa a fase de design visual"""
        context.current_agent = "visual"
        start_time = time.time()
        
        try:
            # Criar tarefa visual com contexto da reda√ß√£o
            task = self.agents_system.create_visual_task(context.request)
            agent = self.agents_system._agents["visual"]
            
            # Adicionar contexto da reda√ß√£o
            enhanced_description = f"""
            {task.description}
            
            **CONTE√öDO TEXTUAL CRIADO:**
            {writing_result.content}
            
            Crie prompts visuais que complementem perfeitamente esse conte√∫do.
            """
            task.description = enhanced_description
            
            # Executar tarefa
            result = agent.execute_task(task)
            
            # Criar resultado estruturado
            agent_result = AgentResult(
                agent_name="visual",
                success=True,
                content=str(result),
                metadata={
                    "task_description": task.description,
                    "writing_context": writing_result.content[:500] + "...",
                    "platforms": context.request.platforms
                },
                execution_time=time.time() - start_time
            )
            
            context.agent_results.append(agent_result)
            
            # Processar feedback writing -> visual
            await self._generate_inter_agent_feedback(
                "writing_to_visual", writing_result, agent_result, context
            )
            
            self.logger.info(
                f"üé® Fase visual conclu√≠da em {agent_result.execution_time:.2f}s"
            )
            
            return agent_result
            
        except Exception as e:
            agent_result = AgentResult(
                agent_name="visual",
                success=False,
                content="",
                metadata={},
                execution_time=time.time() - start_time,
                error_message=str(e)
            )
            
            context.agent_results.append(agent_result)
            raise RuntimeError(f"Erro na fase visual: {e}")
    
    async def _execute_editing_phase(
        self,
        context: ExecutionContext,
        research_result: AgentResult,
        writing_result: AgentResult,
        visual_result: AgentResult
    ) -> AgentResult:
        """Executa a fase de edi√ß√£o final"""
        context.current_agent = "editor"
        start_time = time.time()
        
        try:
            # Criar tarefa de edi√ß√£o com todo o contexto
            task = self.agents_system.create_editing_task(context.request)
            agent = self.agents_system._agents["editor"]
            
            # Adicionar contexto completo
            enhanced_description = f"""
            {task.description}
            
            **PESQUISA REALIZADA:**
            {research_result.content}
            
            **CONTE√öDO TEXTUAL:**
            {writing_result.content}
            
            **PROMPTS VISUAIS:**
            {visual_result.content}
            
            **FEEDBACK DE QUALIDADE:**
            {self._get_quality_feedback_summary(context)}
            
            Avalie todo o conjunto e tome uma decis√£o final de aprova√ß√£o.
            """
            task.description = enhanced_description
            
            # Executar tarefa
            result = agent.execute_task(task)
            
            # Criar resultado estruturado
            agent_result = AgentResult(
                agent_name="editor",
                success=True,
                content=str(result),
                metadata={
                    "task_description": task.description,
                    "evaluated_agents": ["researcher", "writer", "visual"],
                    "feedback_count": len(context.feedback_history)
                },
                execution_time=time.time() - start_time
            )
            
            context.agent_results.append(agent_result)
            
            self.logger.info(
                f"üé¨ Fase de edi√ß√£o conclu√≠da em {agent_result.execution_time:.2f}s"
            )
            
            return agent_result
            
        except Exception as e:
            agent_result = AgentResult(
                agent_name="editor",
                success=False,
                content="",
                metadata={},
                execution_time=time.time() - start_time,
                error_message=str(e)
            )
            
            context.agent_results.append(agent_result)
            raise RuntimeError(f"Erro na fase de edi√ß√£o: {e}")
    
    def _parse_editor_decision(self, editing_result: AgentResult) -> ApprovalDecision:
        """Extrai a decis√£o de aprova√ß√£o do resultado do editor"""
        content = editing_result.content.lower()
        
        if "[aprovado]" in content or "aprovado" in content.split()[:10]:
            return ApprovalDecision.APPROVED
        elif "[rejeitado]" in content or "rejeitado" in content.split()[:10]:
            return ApprovalDecision.REJECTED
        elif "[revis√£o necess√°ria]" in content or "revis√£o" in content.split()[:10]:
            return ApprovalDecision.NEEDS_REVISION
        else:
            # Analisar contexto para inferir decis√£o
            if "excelente" in content or "perfeito" in content or "√≥timo" in content:
                return ApprovalDecision.APPROVED
            elif "precisa melhorar" in content or "n√£o atende" in content:
                return ApprovalDecision.NEEDS_REVISION
            else:
                return ApprovalDecision.PENDING
    
    async def _generate_inter_agent_feedback(
        self,
        feedback_type: str,
        from_result: AgentResult,
        to_result: AgentResult,
        context: ExecutionContext
    ):
        """Gera feedback entre agentes"""
        processor = self.feedback_processors.get(feedback_type)
        if processor:
            feedback = await processor(from_result, to_result, context)
            if feedback:
                context.feedback_history.append(feedback)
                self.logger.info(f"üí¨ Feedback {feedback_type}: {feedback.severity}")
    
    async def _process_research_feedback(
        self, 
        research: AgentResult, 
        writing: AgentResult, 
        context: ExecutionContext
    ) -> Optional[QualityFeedback]:
        """Processa feedback da pesquisa para reda√ß√£o"""
        # Implementar an√°lise de qualidade
        return None  # Placeholder
    
    async def _process_writing_feedback(
        self, 
        writing: AgentResult, 
        visual: AgentResult, 
        context: ExecutionContext
    ) -> Optional[QualityFeedback]:
        """Processa feedback da reda√ß√£o para visual"""
        # Implementar an√°lise de qualidade
        return None  # Placeholder
    
    async def _process_visual_feedback(
        self, 
        visual: AgentResult, 
        editing: AgentResult, 
        context: ExecutionContext
    ) -> Optional[QualityFeedback]:
        """Processa feedback visual para edi√ß√£o"""
        # Implementar an√°lise de qualidade
        return None  # Placeholder
    
    async def _process_editor_feedback(
        self, 
        editing: AgentResult, 
        all_results: AgentResult, 
        context: ExecutionContext
    ) -> Optional[QualityFeedback]:
        """Processa feedback do editor para todos"""
        # Implementar an√°lise de qualidade
        return None  # Placeholder
    
    async def _process_rejection_feedback(
        self, 
        context: ExecutionContext, 
        editing_result: AgentResult
    ):
        """Processa feedback de rejei√ß√£o e prepara nova tentativa"""
        # Extrair feedback espec√≠fico do editor
        context.editor_feedback = self._extract_editor_feedback(editing_result.content)
        
        # Resetar resultados para nova tentativa
        context.agent_results = []
        context.feedback_history = []
        
        self.logger.info(f"üîÑ Processando feedback de rejei√ß√£o: {context.editor_feedback[:100]}...")
    
    async def _process_revision_feedback(
        self, 
        context: ExecutionContext, 
        editing_result: AgentResult
    ):
        """Processa feedback para revis√£o espec√≠fica"""
        # Similar ao rejection mas com abordagem mais focada
        await self._process_rejection_feedback(context, editing_result)
    
    def _extract_editor_feedback(self, editor_content: str) -> str:
        """Extrai feedback espec√≠fico do conte√∫do do editor"""
        lines = editor_content.split('\n')
        feedback_section = []
        in_feedback = False
        
        for line in lines:
            if "feedback" in line.lower() or "melhorias" in line.lower():
                in_feedback = True
            elif in_feedback and line.strip():
                feedback_section.append(line.strip())
            elif in_feedback and not line.strip():
                break
        
        return '\n'.join(feedback_section) if feedback_section else editor_content[:500]
    
    def _get_quality_feedback_summary(self, context: ExecutionContext) -> str:
        """Gera resumo do feedback de qualidade"""
        if not context.feedback_history:
            return "Nenhum feedback de qualidade registrado."
        
        summary = []
        for feedback in context.feedback_history:
            summary.append(
                f"- {feedback.from_agent} ‚Üí {feedback.to_agent}: "
                f"{feedback.feedback_type} ({feedback.severity})"
            )
        
        return '\n'.join(summary)
    
    def _create_final_result(
        self, 
        context: ExecutionContext, 
        editing_result: AgentResult
    ) -> CrewResult:
        """Cria resultado final aprovado"""
        total_time = (datetime.now() - context.start_time).total_seconds()
        
        return CrewResult(
            request=context.request,
            success=True,
            final_content=editing_result.content,
            agent_results=context.agent_results,
            total_execution_time=total_time,
            approval_status="approved",
            revision_feedback=None
        )
    
    def _create_rejection_result(
        self, 
        context: ExecutionContext, 
        editing_result: AgentResult
    ) -> CrewResult:
        """Cria resultado de rejei√ß√£o"""
        total_time = (datetime.now() - context.start_time).total_seconds()
        
        return CrewResult(
            request=context.request,
            success=False,
            final_content="",
            agent_results=context.agent_results,
            total_execution_time=total_time,
            approval_status="rejected",
            revision_feedback=context.editor_feedback
        )
    
    def _create_max_retries_result(self, context: ExecutionContext) -> CrewResult:
        """Cria resultado quando excede tentativas m√°ximas"""
        total_time = (datetime.now() - context.start_time).total_seconds()
        
        return CrewResult(
            request=context.request,
            success=False,
            final_content="",
            agent_results=context.agent_results,
            total_execution_time=total_time,
            approval_status="max_retries_exceeded",
            revision_feedback=f"Excedido limite de {context.max_retries} tentativas"
        )
    
    def _update_metrics(self, context: ExecutionContext, result: CrewResult):
        """Atualiza m√©tricas do orquestrador"""
        self.metrics.total_executions += 1
        
        if result.success:
            self.metrics.successful_executions += 1
        else:
            self.metrics.failed_executions += 1
        
        # Atualizar m√©dia de tempo de execu√ß√£o
        current_avg = self.metrics.avg_execution_time
        total_execs = self.metrics.total_executions
        self.metrics.avg_execution_time = (
            (current_avg * (total_execs - 1) + result.total_execution_time) / total_execs
        )
        
        # Atualizar m√©dia de retries
        current_avg_retries = self.metrics.avg_retries
        self.metrics.avg_retries = (
            (current_avg_retries * (total_execs - 1) + context.retry_count) / total_execs
        )
        
        # Atualizar taxa de aprova√ß√£o
        if self.metrics.total_executions > 0:
            self.metrics.approval_rate = (
                self.metrics.successful_executions / self.metrics.total_executions
            )
    
    def get_execution_status(self, execution_id: str) -> Optional[Dict[str, Any]]:
        """Retorna status de uma execu√ß√£o espec√≠fica"""
        if execution_id in self.active_executions:
            context = self.active_executions[execution_id]
            return {
                "id": execution_id,
                "status": context.status.value,
                "current_agent": context.current_agent,
                "retry_count": context.retry_count,
                "agents_completed": len(context.agent_results),
                "elapsed_time": (datetime.now() - context.start_time).total_seconds()
            }
        return None
    
    def get_active_executions(self) -> List[Dict[str, Any]]:
        """Retorna lista de execu√ß√µes ativas"""
        return [
            self.get_execution_status(exec_id) 
            for exec_id in self.active_executions.keys()
        ]
    
    def get_metrics(self) -> OrchestrationMetrics:
        """Retorna m√©tricas atuais"""
        return self.metrics
    
    def get_recent_history(self, limit: int = 10) -> List[ExecutionContext]:
        """Retorna hist√≥rico recente de execu√ß√µes"""
        return sorted(
            self.execution_history,
            key=lambda x: x.start_time,
            reverse=True
        )[:limit]

# Inst√¢ncia global do orquestrador
content_orchestrator = ContentOrchestrator()

# Fun√ß√µes de conveni√™ncia
async def create_content_orchestrated(
    topic: str,
    platforms: List[str] = ["instagram", "whatsapp", "linkedin"],
    target_audience: str = "P√∫blico geral",
    objective: str = "Engajamento e compartilhamento",
    tone: Optional[str] = None,
    special_instructions: Optional[str] = None
) -> CrewResult:
    """Fun√ß√£o de conveni√™ncia para cria√ß√£o orquestrada de conte√∫do"""
    request = ContentRequest(
        topic=topic,
        platforms=platforms,
        target_audience=target_audience,
        objective=objective,
        tone=tone,
        special_instructions=special_instructions
    )
    
    return await content_orchestrator.create_content(request)

def get_orchestration_metrics() -> OrchestrationMetrics:
    """Fun√ß√£o de conveni√™ncia para obter m√©tricas"""
    return content_orchestrator.get_metrics()

def get_active_orchestrations() -> List[Dict[str, Any]]:
    """Fun√ß√£o de conveni√™ncia para obter execu√ß√µes ativas"""
    return content_orchestrator.get_active_executions()
